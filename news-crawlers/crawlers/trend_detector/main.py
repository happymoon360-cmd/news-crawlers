#!/usr/bin/env python3
"""
Trend Detector - Daily trend analysis using z.ai Coding Plan (GLM-5)
"""

import os
import requests
from datetime import datetime
from pathlib import Path
from openai import OpenAI

# Configuration - z.ai Coding Plan API
Z_AI_API_KEY = os.environ.get("Z_AI_API_KEY")
Z_AI_BASE_URL = os.environ.get("Z_AI_BASE_URL", "https://api.z.ai/api/openai/v1")
MODEL = "glm-5"
TIMEOUT = 600  # 10 minutes

OUTPUT_DIR = Path("/tmp/output")
DATE = datetime.now().strftime("%Y-%m-%d")

client = OpenAI(
    api_key=Z_AI_API_KEY,
    base_url=Z_AI_BASE_URL,
    timeout=TIMEOUT
)


def fetch_google_trends(geo: str = "US") -> list:
    """Fetch trending searches from Google Trends RSS"""
    url = f"https://trends.google.com/trends/trendingsearches/daily/rss?geo={geo}"
    try:
        resp = requests.get(url, timeout=60)
        trends = []
        items = resp.text.split("<item>")
        for item in items[1:11]:
            title_start = item.find("<title>")
            title_end = item.find("</title>")
            if title_start != -1 and title_end != -1:
                title = item[title_start+7:title_end]
                traffic_start = item.find("<ht:approx_traffic>")
                traffic_end = item.find("</ht:approx_traffic>")
                traffic = item[traffic_start+19:traffic_end] if traffic_start != -1 else "N/A"
                trends.append({"keyword": title, "traffic": traffic})
        return trends
    except Exception as e:
        print(f"Error fetching Google Trends: {e}")
        return []


def analyze_trend(trend_data: dict, trend_type: str) -> str:
    """Analyze why a trend is viral using z.ai API"""
    if not Z_AI_API_KEY:
        return "API í‚¤ ì—†ìŒ"

    prompt = f"""ë‹¤ìŒ íŠ¸ë Œë“œê°€ ì™œ ë°”ì´ëŸ´ë˜ì—ˆëŠ”ì§€ í•œêµ­ì–´ë¡œ 2-3ë¬¸ì¥ìœ¼ë¡œ ë¶„ì„í•´ì¤˜.

íŠ¸ë Œë“œ ìœ í˜•: {trend_type}
í‚¤ì›Œë“œ: {trend_data.get('keyword', 'Unknown')}
ê²€ìƒ‰ëŸ‰: {trend_data.get('traffic', 'N/A')}
ë‚ ì§œ: {DATE}

ë¶„ì„:"""

    try:
        response = client.chat.completions.create(
            model=MODEL,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=300
        )
        return response.choices[0].message.content or "ë¶„ì„ ì‹¤íŒ¨"
    except Exception as e:
        print(f"API Error: {e}")
        return f"ë¶„ì„ ì˜¤ë¥˜: {e}"


def generate_report(us_trends: list, kr_trends: list) -> str:
    """Generate markdown report"""

    frontmatter = f"""---
title: íŠ¸ë Œë“œ ê°ì§€ ë¦¬í¬íŠ¸
date: {DATE}
type: resource
topics:
  - í‚¤ì›Œë“œ
  - íŠ¸ë Œë“œ
source: ë‰´ìŠ¤
---
# ğŸ”¥ ê¸‰ìƒìŠ¹ íŠ¸ë Œë“œ ë¶„ì„ - {DATE}
"""

    content = ""

    if us_trends:
        content += "## ğŸŒ US Trends\n\n### ğŸ“Š Google Trends\n"
        for trend in us_trends[:5]:
            analysis = analyze_trend(trend, "Google Trends US")
            content += f"""#### {trend['keyword']} (â†‘ {trend['traffic']})
**ë°”ì´ëŸ´ ì´ìœ **: {analysis}

"""

    if kr_trends:
        content += "---\n\n## ğŸ‡°ğŸ‡· KR Trends\n\n### ğŸ“Š Google Trends\n"
        for trend in kr_trends[:5]:
            analysis = analyze_trend(trend, "Google Trends KR")
            content += f"""#### {trend['keyword']} (â†‘ {trend['traffic']})
**ë°”ì´ëŸ´ ì´ìœ **: {analysis}

"""

    content += "\n---\n#type/resource #topic/í‚¤ì›Œë“œ #source/ë‰´ìŠ¤\n"
    return frontmatter + content


def main():
    print(f"Starting Trend Detector - {DATE}")
    print(f"Using model: {MODEL}")
    print(f"API endpoint: {Z_AI_BASE_URL}")

    us_trends = fetch_google_trends("US")
    kr_trends = fetch_google_trends("KR")

    print(f"US Trends: {len(us_trends)}, KR Trends: {len(kr_trends)}")

    report = generate_report(us_trends, kr_trends)

    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    output_file = OUTPUT_DIR / f"íŠ¸ë Œë“œ_ê°ì§€_{DATE}.md"

    with open(output_file, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"Report saved: {output_file}")
    print("\n--- Report Preview ---")
    print(report[:500] + "...")


if __name__ == "__main__":
    main()
